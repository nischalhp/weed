{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_df = pd.DataFrame.from_csv(\"marijuana-street-price-clean.csv\",header=0,index_col=False,sep=',',parse_dates=[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#csv_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_df_sort = csv_df.sort(columns=['State','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let us count the number of entries in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_df_sort.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_df_sort.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we see that LowQ does not match the number of entries and this a common problem in time series analysis\n",
    "# lets fill up the Nan value with the last known best value so that we can work on continuing time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_df_sort_fillna_ffil = csv_df_sort.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_df_sort_fillna_ffil.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we have cleaned data set to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_mean_HighQ = csv_df_sort_fillna_ffil['HighQ'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_mean_HighQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now that we have the global mean, we can find how far the values of mean are for each state from global mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(csv_df_sort_fillna_ffil.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#group_by_state.get_group(('Alabama'))\n",
    "# to check values for a given group\n",
    "# now lets use agg function to get generate Mean,Median,Standard deviation,Variance and covariance for every state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basic_measures_state_wise_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lets get all the unique states in the data frame and construct the measures for each state\n",
    "# normal method\n",
    "'''\n",
    "unique_states = pd.unique(csv_df_sort_fillna_ffil['State'].ravel())\n",
    "for state in unique_states:\n",
    "    state_df = csv_df_sort_fillna_ffil.loc[csv_df_sort_fillna_ffil['State'] == state]\n",
    "    highq_df = state_df.groupby(['State'])['HighQ'].agg([np.mean,np.median,np.std,np.var,np.cov])\n",
    "    highq_df.head()\n",
    "    lowq_df = state_df.groupby(['State'],)['LowQ'].agg([np.mean,np.median,np.std,np.var,np.cov])\n",
    "    highq_df = highq_df.rename(columns={'mean':'HighQ_Mean','median':'HighQ_Median','std':'HighQ_Std','var':'HighQ_Var','cov':'HighQ_Cov'})\n",
    "    lowq_df = lowq_df.rename(columns={'mean':'LowQ_Mean','median':'LowQ_Median','std':'LowQ_Std','var':'LowQ_Var','cov':'LowQ_Cov'})\n",
    "    highq_df['State'] = state\n",
    "    lowq_df['State'] = state\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_df_sort_fillna_ffil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statistics_df = pd.DataFrame(csv_df_sort_fillna_ffil.groupby(['State'],as_index=False).aggregate\\\n",
    "                             ({'HighQ': {'HighQ_Mean': np.mean,'HighQ_Median':np.median,'HighQ_Mode':stats.mode,'HighQ_Std':np.std,'HighQ_Var':np.var,'HighQ_Covar':np.cov},\\\n",
    "                               'LowQ':{'LowQ_Mean':np.mean,'LowQ_Median':np.median,'LowQ_Mode':stats.mode,'LowQ_Std':np.std,'LowQ_Var':np.var,'LowQ_Covar':np.cov}}))\n",
    "print type(statistics_df)\n",
    "statistics_df = statistics_df.rename(columns={'':'State'})\n",
    "print type(statistics_df)\n",
    "statistics_df.columns = statistics_df.columns.droplevel(0)\n",
    "statistics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let us now read demographics data into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demographics_df = pd.DataFrame.from_csv(\"Demographics_State.csv\",header=0,index_col=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demographics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demographics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demographics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let us now read population data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population_df = pd.DataFrame.from_csv(\"Population_State.csv\",header=0,index_col=False,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we are now merging demographic and population data into one single data frame\n",
    "#to do this , we are using pandas merge method which allows us to join two data frames like how we do it in sql\n",
    "# we are using inner join and on the column region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population_demographic_merge_df = pd.merge(demographics_df,population_df,how='inner',on='region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population_demographic_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population_demographic_merge_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population_demographic_merge_df = population_demographic_merge_df.rename(columns={'region':'State'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population_demographic_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statistics_population_demographic_merge_df = pd.merge(population_demographic_merge_df,statistics_df,how='inner',on='State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statistics_population_demographic_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the reason why there are no entries here is because in the population demographic df the States are in lower case\n",
    "# let us now change the States to lower case in statistics df too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statistics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statistics_df['State'] = statistics_df['State'].str.lower()\n",
    "statistics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now lets merge the data again, the reason we are merging all this data is we are able to look at one state on multiple levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats_pop_dem_merge_df = pd.merge(population_demographic_merge_df,statistics_df,how='inner',on='State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats_pop_dem_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats_pop_dem_merge_df.shape\n",
    "stats_pop_dem_merge_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#so now we have data for 51 states with 20 feature columns. \n",
    "#The data is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_greater_black = stats_pop_dem_merge_df[stats_pop_dem_merge_df.percent_white > stats_pop_dem_merge_df.percent_black]\n",
    "black_greate_white =  stats_pop_dem_merge_df[stats_pop_dem_merge_df.percent_white < stats_pop_dem_merge_df.percent_black]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_greater_black.shape,black_greate_white.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#given that the white population is high in almost every state, lets not do any comparison use the \n",
    "#percent of whites and blacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#let us see if there is a correlation between per capita income and highQ_mean/lowQ_mean\n",
    "correlation_btw_per_capita_highQ = stats.pearsonr(white_greater_black.per_capita_income,white_greater_black.HighQ_Mean)[0]\n",
    "correlation_btw_per_capita_lowQ = stats.pearsonr(white_greater_black.per_capita_income,white_greater_black.LowQ_Mean)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlation_btw_per_capita_highQ,correlation_btw_per_capita_lowQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using population data let us see if we can correlate total population with that of price\n",
    "population_correlation = stats.pearsonr(stats_pop_dem_merge_df.total_population,stats_pop_dem_merge_df.HighQ_Mean)[0]\n",
    "population_correlation\n",
    "\n",
    "# we see that it is iversely correlated to an extent which implies greater the population lesser is the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let us see if there is a big difference in the value of High quality \n",
    "# weed prices based on states selling it legally and those that dont\n",
    "legal_states = ['colorado']\n",
    "illegal_states = ['wyoming']\n",
    "\n",
    "legal_states_mean = stats_pop_dem_merge_df[stats_pop_dem_merge_df['State'].isin(legal_states)]['HighQ_Mean']\n",
    "illegal_states_mean = stats_pop_dem_merge_df[stats_pop_dem_merge_df['State'].isin(illegal_states)]['HighQ_Mean']\n",
    "legal_states_mean = legal_states_mean.reset_index()\n",
    "illegal_states_mean = illegal_states_mean.reset_index()\n",
    "print legal_states_mean.head()\n",
    "print illegal_states_mean.head()\n",
    "\n",
    "# we see that legal states sell highQ marijuana at a lesser price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from this we understand that the value of low quality weed is somewhat affected by per capita income compared to \n",
    "# high quality weed\n",
    "# we can use the same way to compute correlations amognst other attributes too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#before we go any further , lets try to find some interesting growth in weed prices for each state \n",
    "csv_df_sort_fillna_ffil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_mean_highQ = csv_df_sort_fillna_ffil.groupby(['date'],as_index=False).aggregate({'HighQ':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_mean_highQ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_mean_highQ.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we just have dates, we need to generate calendar week for each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# date format in %Y-%m-%d\n",
    "def get_calendar_week(date):\n",
    "    calendar_week = date.isocalendar()[1]\n",
    "    return int(calendar_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets add calendar week to the data frame\n",
    "csv_df_sort_fillna_ffil['Calendar_Week'] = csv_df_sort_fillna_ffil['date'].apply(get_calendar_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lets check if it looks fine\n",
    "csv_df_sort_fillna_ffil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now let us try to group at week level and see during which week it was the lowest and for a given state\n",
    "country_week_highQ_df = pd.DataFrame(csv_df_sort_fillna_ffil.groupby(['Calendar_Week'],as_index=False).aggregate({'HighQ':{'HighQ_Mean':np.mean}}))\n",
    "country_week_highQ_df.columns = country_week_highQ_df.columns.droplevel(0)\n",
    "country_week_highQ_df = country_week_highQ_df.rename(columns={'':'Calendar_Week'})\n",
    "country_week_highQ_df.head()\n",
    "print country_week_highQ_df.min(),country_week_highQ_df.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now let us check on which day it was the lowest across country\n",
    "country_day_highQ_df = pd.DataFrame(csv_df_sort_fillna_ffil.groupby(['date'],as_index=False).aggregate({'HighQ':{'HighQ_Mean':np.mean}}))\n",
    "country_day_highQ_df.columns = country_day_highQ_df.columns.droplevel(0)\n",
    "country_day_highQ_df = country_day_highQ_df.rename(columns={'':'date'})\n",
    "country_day_highQ_df.head()\n",
    "print country_day_highQ_df.min(),country_day_highQ_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now let us check when people buy the most across the country \n",
    "country_week_highQN_df = pd.DataFrame(csv_df_sort_fillna_ffil.groupby(['Calendar_Week'],as_index=False).aggregate({'HighQN':{'HighQN_Mean':np.mean}}))\n",
    "country_week_highQN_df.columns = country_week_highQN_df.columns.droplevel(0)\n",
    "country_week_highQN_df = country_week_highQN_df.rename(columns={'':'Calendar_Week'})\n",
    "country_week_highQN_df.head()\n",
    "print country_week_highQN_df.min(),country_week_highQN_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The above set of statements work across the country based on date and calendar week\n",
    "# Now let us look at what happens every month by generating calendar week for a month and then see during which parts \n",
    "# of the month the price is at its highest/lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_calendar_week_month(date):\n",
    "    calendar_week_year = get_calendar_week(date)\n",
    "    month = date.month\n",
    "    year = date.year\n",
    "    day = date.day\n",
    "    start_of_month = str(year)+\"-\"+str(month)+\"-\"+\"01\"\n",
    "    calendar_week_start_of_month = date.isocalendar()[1]\n",
    "    # this happens only for dec\n",
    "    if(calendar_week_year > calendar_week_start_of_month):\n",
    "        return calendar_week_year - calendar_week_start_of_month + 1\n",
    "    else:\n",
    "        return calendar_week_year\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the function to generate calendar_Week_month works\n",
    "get_calendar_week_month(datetime.strptime(\"2013-12-30\",\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_df_sort_fillna_ffil['Calendar_Week_Month'] = csv_df_sort_fillna_ffil['date'].apply(get_calendar_week_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_df_sort_fillna_ffil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now let us try to group at week level and see during which week it was the lowest and for a given state\n",
    "country_month_week_highQ_df = pd.DataFrame(csv_df_sort_fillna_ffil.groupby(['Calendar_Week_Month'],as_index=False).aggregate({'HighQ':{'HighQ_Mean':np.mean}}))\n",
    "country_month_week_highQ_df.columns = country_month_week_highQ_df.columns.droplevel(0)\n",
    "country_month_week_highQ_df = country_month_week_highQ_df.rename(columns={'':'Calendar_Week_Month'})\n",
    "country_month_week_highQ_df.head()\n",
    "print  country_month_week_highQ_df.min()\n",
    "print country_month_week_highQ_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_df_sort_fillna_ffil.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now we have some insights into the data , let us take the next step and use a liner regression model to predict the \n",
    "# prices of marijuana for the state alabama\n",
    "columns_required = ['State','HighQ','date']\n",
    "alabama_state = csv_df_sort_fillna_ffil[csv_df_sort_fillna_ffil['State'] == \"Alabama\"]\n",
    "alabama_state_price_date = alabama_state.ix[:,columns_required]\n",
    "alabama_state_price_date.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train,test = train_test_split(alabama_state_price_date,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def changeDateToOrdinal(date):\n",
    "    return date.toordinal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pd = pd.DataFrame(train,columns=['State','Price','Date'])\n",
    "train_pd['State'] = 1\n",
    "train_pd['Price'] = train_pd['Price'].astype(float)\n",
    "train_pd['Date_ord'] = train_pd['Date'].apply(changeDateToOrdinal)\n",
    "\n",
    "train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pd = pd.DataFrame(test,columns=['State','Price','Date'])\n",
    "test_pd['State'] =1\n",
    "test_pd['Price'] = test_pd['Price'].astype(float)\n",
    "test_pd['Date_ord'] = test_pd['Date'].apply(changeDateToOrdinal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_pd.head()\n",
    "train_pd.dtypes\n",
    "\n",
    "print test_pd.head()\n",
    "test_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = train_pd.ix[:,['State','Date_ord']]\n",
    "y_train = train_pd.ix[:,['Price']]\n",
    "print x_train.dtypes,y_train.dtypes\n",
    "x_test = test_pd.ix[:,['State','Date_ord']]\n",
    "y_test = test_pd.ix[:,['Price']]\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train.head()\n",
    "y_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print x_train.head()\n",
    "x_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression(normalize=True, fit_intercept=True)\n",
    "ols.fit(x_train, y_train, n_jobs=-1)\n",
    " \n",
    "print ols.coef_\n",
    "ols_predict = ols.predict(x_test)\n",
    " \n",
    "#print ols_predict\n",
    "#Setting 0.5 as the decision boundary. If values are above 0.5, the prediction is set to 1. This means the record belongs to class 2. Else, the prediction is set to 0\n",
    " \n",
    "test_pd['Predicted_Price'] = ols_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
